<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Wardley Maps Demo</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        max-width: 1200px;
        margin: 20px auto;
        padding: 0 20px;
        background: #f5f5f5;
      }
      h1 {
        color: #333;
      }
      .example {
        background: white;
        padding: 20px;
        margin: 20px 0;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
      }
      .example h2 {
        margin-top: 0;
        color: #0066cc;
      }
      pre {
        background: #f8f8f8;
        padding: 15px;
        border-radius: 4px;
        overflow-x: auto;
      }
      .mermaid {
        max-width: 100%;
        overflow: visible;
      }
      .mermaid svg {
        max-width: 100%;
        height: auto;
      }
    </style>
  </head>
  <body>
    <h1>Wardley Maps Diagrams</h1>
    <p>Strategic positioning diagrams as code!</p>

    <div class="example">
      <h2>Example 1: Tea Shop</h2>
      <pre class="mermaid">
wardley-beta
title Tea Shop
size [1100, 800]

anchor Business [0.95, 0.63]
anchor Public [0.95, 0.78]
component Cup of Tea [0.79, 0.61] label [19, -4]
component Cup [0.73, 0.78]
component Tea [0.63, 0.81]
component Hot Water [0.52, 0.80]
component Water [0.38, 0.82]
component Kettle [0.43, 0.35] label [-57, 4]
component Power [0.1, 0.7] label [-27, 20]

Business -> Cup of Tea
Public -> Cup of Tea
Cup of Tea -> Cup
Cup of Tea -> Tea
Cup of Tea -> Hot Water
Hot Water -> Water
Hot Water -> Kettle
Kettle -> Power

evolve Kettle 0.62
evolve Power 0.89

note Standardising power allows Kettles to evolve faster [0.30, 0.49]
note Hot water is obvious and well known [0.48, 0.80]
      </pre>
    </div>

    <div class="example">
      <h2>Example 2: Data Evolution Stages</h2>
      <pre class="mermaid">
wardley-beta
title Data Evolution Pipeline
size [1100, 800]

evolution Unmodelled -> Divergent -> Convergent -> Modelled

component User Needs [0.95, 0.05]
component Data Collection [0.80, 0.15]
component Custom Analytics [0.70, 0.35]
component Standardized Reports [0.65, 0.65]
component Commodity Storage [0.60, 0.85]

User Needs -> Data Collection
Data Collection -> Custom Analytics
Custom Analytics -> Standardized Reports
Standardized Reports -> Commodity Storage

evolve Custom Analytics 0.60
evolve Standardized Reports 0.85
      </pre>
    </div>

    <div class="example">
      <h2>Example 3: Pipelines (Component Y-axis Inheritance)</h2>
      <pre class="mermaid">
wardley-beta
title Kettle Evolution Pipeline
size [1100, 800]

component Kettle [0.57, 0.45]
component Power [0.10, 0.70]

Kettle -> Power

pipeline Kettle {
  component Campfire Kettle [0.35] label [-60, 35]
  component Electric Kettle [0.53] label [-60, 35]
  component Smart Kettle [0.72] label [-30, 35]
}

Campfire Kettle -> Kettle
Electric Kettle -> Kettle
Smart Kettle -> Kettle
      </pre>
    </div>

    <div class="example">
      <h2>Example 4: Link Types and Annotations</h2>
      <pre class="mermaid">
wardley-beta
title Link Features Demo
size [1100, 800]

component User [0.95, 0.90]
component App [0.75, 0.75]
component API [0.60, 0.60]
component Cache [0.65, 0.45]
component Database [0.15, 0.80]
component Service [0.45, 0.50]

User -> App
App +> API; +>
API -> Database; constraint
API +<> Cache; +<>
Cache +< Service; +<
Service +'backup'> Database
      </pre>
    </div>

    <div class="example">
      <h2>Example 5: Custom Canvas Size</h2>
      <pre class="mermaid">
wardley-beta
title Custom Size Map
size [600, 800]

anchor User [0.95, 0.90]
component App [0.75, 0.85]
component API [0.50, 0.70]
component Database [0.30, 0.50]
component Cloud [0.15, 0.30]

User -> App
App -> API
API -> Database
Database -> Cloud

evolve Database 0.60
      </pre>
    </div>

    <div class="example">
      <h2>Example 6: GPT Tokeniser Architecture</h2>
      <p>
        Complex AI system showing tokeniser components, evolution pipelines, and technical
        dependencies.
      </p>
      <pre class="mermaid">
wardley-beta
title GPT Tokeniser
size [1100, 800]

anchor GPT Tokeniser [0.90, 0.58]

component tokeniser [0.81, 0.58]
component encoder [0.60, 0.32] label [1, -9]
component decoder [0.60, 0.72]
component methodology [0.72, 0.53]
component training code [0.68, 0.26] label [-90, 2]
component inference code [0.65, 0.37] label [-50, -12]
component algo [0.53, 0.50] label [-15, -17]
component GPT2 [0.81, 0.65] label [-14, 27]
component GPT3 [0.81, 0.73] label [-15, 27]
component GPT4 [0.81, 0.77] label [-14, 28]
component GPT5 [0.81, 0.37] label [-10, 28]
component GPT6 [0.81, 0.17] label [-20, 28]
component GPT7 [0.81, 0.13] label [-13, 27]
component tokeniser training data [0.29, 0.34] label [-74, -32]
component special tokens [0.59, 0.26] label [-61, 15]
component UTF8 [0.17, 0.74]
component token vocabulary [0.41, 0.56] label [-25, 16]
component byte pair encoding (BPE) [0.53, 0.76] label [-27, 19]
component english text data [0.15, 0.37] label [0, 10]
component code data [0.15, 0.30] label [-31, 23]
component foreign text data [0.15, 0.23] label [-51, 18]
component python [0.35, 0.84]
component sentencepiece [0.25, 0.80] label [-49, 19]
component IDE [0.27, 0.86]
component MEGABYTE [0.53, 0.18] label [-28, 28]
component text merging rules [0.60, 0.21] label [-64, -10]
component security framework [0.67, 0.58] label [-27, 10]
component Unicode Consortium [0.06, 0.55]
component Unicode License v3 [0.13, 0.72] label [-29, 11]

GPT Tokeniser -> tokeniser

tokeniser -> methodology
methodology -> training code
methodology -> inference code
methodology -> security framework

training code -> special tokens
training code -> python

algo -> tokeniser training data
training code -> text merging rules

training code -> encoder
inference code -> decoder
encoder -> algo
decoder -> algo

algo -> token vocabulary

byte pair encoding (BPE) -> UTF8
MEGABYTE -> UTF8
UTF8 -> Unicode License v3
Unicode License v3 -> Unicode Consortium

tokeniser training data -> english text data
tokeniser training data -> code data
tokeniser training data -> foreign text data

python -> IDE
python -> sentencepiece

pipeline tokeniser {
  component tokeniser v1 [0.11]
  component tokeniser v2 [0.80]
}

pipeline methodology {
  component methodology v1 [0.20]
  component methodology v2 [0.80]
}

pipeline algo {
  component algo v1 [0.14]
  component algo v2 [0.80]
}

deaccelerator License Play [0.13, 0.78]

annotations [1, 0]
annotation 1,[0.57, 0.16] Alternative algos in research
annotation 2,[0.57, 0.76] Most popular, but not the most efficient
annotation 3,[0.20, 0.3] Ensure balanced token vocabulary
annotation 4,[0.60, 0.28] Required for delimiters
annotation 5,[0.70, 0.50] A structured approach for achieving a goal

note Voting members: Adobe, Amazon, Apple, Google, Meta, Microsoft, Netflix, Salesforce [0.04, 0.35]
      </pre>
    </div>

    <script type="module">
      import mermaid from '/mermaid.esm.mjs';

      mermaid.initialize({
        startOnLoad: true,
        theme: 'default',
        logLevel: 'debug',
      });
    </script>
  </body>
</html>
